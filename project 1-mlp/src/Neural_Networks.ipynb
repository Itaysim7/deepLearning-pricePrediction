{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0  loss: 60570374000.0\n",
      "Iteration: 1000  loss: 507317500.0\n",
      "Iteration: 2000  loss: 409431260.0\n",
      "Iteration: 3000  loss: 357374660.0\n",
      "Iteration: 4000  loss: 330048480.0\n",
      "Iteration: 5000  loss: 310098180.0\n",
      "Iteration: 6000  loss: 298672500.0\n",
      "Iteration: 7000  loss: 290861300.0\n",
      "Iteration: 8000  loss: 285260060.0\n",
      "Iteration: 9000  loss: 281113500.0\n",
      "Iteration: 10000  loss: 277724960.0\n",
      "Iteration: 11000  loss: 275184830.0\n",
      "Iteration: 12000  loss: 273304740.0\n",
      "Iteration: 13000  loss: 270469800.0\n",
      "Iteration: 14000  loss: 270937470.0\n",
      "Iteration: 15000  loss: 268509380.0\n",
      "Iteration: 16000  loss: 267385420.0\n",
      "Iteration: 17000  loss: 266545900.0\n",
      "Iteration: 18000  loss: 267685260.0\n",
      "Iteration: 19000  loss: 267401400.0\n",
      "Iteration: 20000  loss: 263778370.0\n",
      "Iteration: 21000  loss: 266249330.0\n",
      "Iteration: 22000  loss: 262202560.0\n",
      "Iteration: 23000  loss: 263858450.0\n",
      "Iteration: 24000  loss: 263114300.0\n",
      "Iteration: 25000  loss: 260350940.0\n",
      "Iteration: 26000  loss: 258793170.0\n",
      "Iteration: 27000  loss: 260912290.0\n",
      "Iteration: 28000  loss: 257740700.0\n",
      "Iteration: 29000  loss: 256707200.0\n",
      "Iteration: 30000  loss: 258232260.0\n",
      "Iteration: 31000  loss: 257072980.0\n",
      "Iteration: 32000  loss: 254929220.0\n",
      "Iteration: 33000  loss: 253541300.0\n",
      "Iteration: 34000  loss: 257228350.0\n",
      "Iteration: 35000  loss: 253962830.0\n",
      "Iteration: 36000  loss: 250837630.0\n",
      "Iteration: 37000  loss: 253590160.0\n",
      "Iteration: 38000  loss: 249464160.0\n",
      "Iteration: 39000  loss: 249605090.0\n",
      "Iteration: 40000  loss: 249102430.0\n",
      "Iteration: 41000  loss: 250071120.0\n",
      "Iteration: 42000  loss: 248212200.0\n",
      "Iteration: 43000  loss: 249296200.0\n",
      "Iteration: 44000  loss: 250379520.0\n",
      "Iteration: 45000  loss: 247340960.0\n",
      "Iteration: 46000  loss: 246804350.0\n",
      "Iteration: 47000  loss: 248530180.0\n",
      "Iteration: 48000  loss: 247261760.0\n",
      "Iteration: 49000  loss: 248771950.0\n",
      "Iteration: 50000  loss: 248725090.0\n",
      "Iteration: 51000  loss: 248010750.0\n",
      "Iteration: 52000  loss: 248067100.0\n",
      "Iteration: 53000  loss: 245378050.0\n",
      "Iteration: 54000  loss: 244255650.0\n",
      "Iteration: 55000  loss: 245835040.0\n",
      "Iteration: 56000  loss: 244761550.0\n",
      "Iteration: 57000  loss: 245237250.0\n",
      "Iteration: 58000  loss: 244678800.0\n",
      "Iteration: 59000  loss: 245892210.0\n",
      "Iteration: 60000  loss: 244572260.0\n",
      "Iteration: 61000  loss: 245233220.0\n",
      "Iteration: 62000  loss: 243476940.0\n",
      "Iteration: 63000  loss: 242978880.0\n",
      "Iteration: 64000  loss: 243325390.0\n",
      "Iteration: 65000  loss: 242731100.0\n",
      "Iteration: 66000  loss: 243224930.0\n",
      "Iteration: 67000  loss: 243175380.0\n",
      "Iteration: 68000  loss: 242497580.0\n",
      "Iteration: 69000  loss: 242999700.0\n",
      "Iteration: 70000  loss: 244285150.0\n",
      "Iteration: 71000  loss: 243312430.0\n",
      "Iteration: 72000  loss: 242848540.0\n",
      "Iteration: 73000  loss: 242318260.0\n",
      "Iteration: 74000  loss: 242151410.0\n",
      "Iteration: 75000  loss: 242985070.0\n",
      "Iteration: 76000  loss: 244304220.0\n",
      "Iteration: 77000  loss: 243688350.0\n",
      "Iteration: 78000  loss: 241512510.0\n",
      "Iteration: 79000  loss: 243280020.0\n",
      "Iteration: 80000  loss: 243318740.0\n",
      "Iteration: 81000  loss: 241459920.0\n",
      "Iteration: 82000  loss: 243695920.0\n",
      "Iteration: 83000  loss: 241900500.0\n",
      "Iteration: 84000  loss: 242665900.0\n",
      "Iteration: 85000  loss: 242340900.0\n",
      "Iteration: 86000  loss: 242247650.0\n",
      "Iteration: 87000  loss: 242796670.0\n",
      "Iteration: 88000  loss: 241315460.0\n",
      "Iteration: 89000  loss: 241902530.0\n",
      "Iteration: 90000  loss: 242214160.0\n",
      "Iteration: 91000  loss: 241246220.0\n",
      "Iteration: 92000  loss: 242692590.0\n",
      "Iteration: 93000  loss: 241151140.0\n",
      "Iteration: 94000  loss: 242099220.0\n",
      "Iteration: 95000  loss: 241646260.0\n",
      "Iteration: 96000  loss: 241392270.0\n",
      "Iteration: 97000  loss: 240710770.0\n",
      "Iteration: 98000  loss: 241847400.0\n",
      "Iteration: 99000  loss: 241186940.0\n",
      "Iteration: 100000  loss: 241288850.0\n",
      " Test error: 320898900.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# Take all the data from the CSV file.and split it to price and mat of all fitchers\n",
    "data=pd.read_csv('Daegu_Real_Estate_data_38_feature.csv')\n",
    "data_y=data['SalePrice']\n",
    "data_x=data.drop('SalePrice',axis = 1)\n",
    "\n",
    "#HallWayType change text values to numrical values.\n",
    "data_x['HallwayType'] =data_x['HallwayType'].astype('category')\n",
    "data_x['HallwayType'] =data_x['HallwayType'].cat.reorder_categories(['corridor','mixed','terraced'],ordered=True)\n",
    "data_x['HallwayType'] =data_x['HallwayType'].cat.codes\n",
    "\n",
    "#HeatingType change text values to numrical values.\n",
    "data_x['HeatingType'] =data_x['HeatingType'].astype('category')\n",
    "data_x['HeatingType'] =data_x['HeatingType'].cat.reorder_categories(['individual_heating','central_heating'],ordered=True)\n",
    "data_x['HeatingType'] =data_x['HeatingType'].cat.codes\n",
    "\n",
    "#AptManageType change text values to numrical values.\n",
    "data_x['AptManageType'] =data_x['AptManageType'].astype('category')\n",
    "data_x['AptManageType'] =data_x['AptManageType'].cat.reorder_categories(['self_management','management_in_trust'],ordered=True)\n",
    "data_x['AptManageType'] =data_x['AptManageType'].cat.codes\n",
    "\n",
    "#TimeToBusStop change text values to numrical values.\n",
    "data_x['TimeToSubway'] =data_x['TimeToSubway'].astype('category')\n",
    "data_x['TimeToSubway'] =data_x['TimeToSubway'].cat.reorder_categories(['no_bus_stop_nearby','15min~20min','10min~15min',\"5min~10min\",\"0-5min\"],ordered=True)\n",
    "data_x['TimeToSubway'] =data_x['TimeToSubway'].cat.codes\n",
    "\n",
    "#TimeToSubway change text values to numrical values.\n",
    "data_x['TimeToBusStop'] =data_x['TimeToBusStop'].astype('category')\n",
    "data_x['TimeToBusStop'] =data_x['TimeToBusStop'].cat.reorder_categories(['10min~15min','5min~10min','0~5min'],ordered=True)\n",
    "data_x['TimeToBusStop'] =data_x['TimeToBusStop'].cat.codes\n",
    "\n",
    "data_x_scaled=(data_x-data_x.mean())/data_x.std()#normalization \n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(data_x_scaled,data_y,test_size=0.3,random_state=0)\n",
    "\n",
    "new_x_train=np.array(x_train)\n",
    "new_y_train = np.array(y_train)\n",
    "new_x_test = np.array(x_test)\n",
    "new_y_test = np.array(y_test)\n",
    "\n",
    "new_y_train = new_y_train.reshape(y_train.shape[0],1)\n",
    "new_y_test = new_y_test.reshape(y_test.shape[0],1)\n",
    "\n",
    "learning_rate = 0.0000005\n",
    "features =38\n",
    "hidden1_size=150\n",
    "training_epochs = 100000\n",
    "\n",
    "#pre proccesing..\n",
    "x = tf.placeholder(tf.float32, [None, features])\n",
    "y_ = tf.placeholder(tf.float32, [None, 1])\n",
    "W1 = tf.Variable(tf.truncated_normal([features, hidden1_size], stddev=0.1))\n",
    "b1 = tf.Variable(tf.constant(0.1, shape=[hidden1_size]))\n",
    "z1 = tf.nn.relu(tf.matmul(x,W1)+b1)\n",
    "W2 = tf.Variable(tf.truncated_normal([hidden1_size, 1], stddev=0.1))\n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[1]))\n",
    "\n",
    "y = tf.matmul(z1,W2)+b2\n",
    "\n",
    "loss = tf.reduce_mean(tf.pow(y-y_,2))\n",
    "update = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(0,training_epochs+1):\n",
    "    sess.run(update, feed_dict = {x:new_x_train, y_:new_y_train})\n",
    "    if i%1000==0:\n",
    "        print('Iteration:' , i , ' loss:', loss.eval(session=sess, feed_dict = {x:new_x_train, y_:new_y_train}))\n",
    "print( ' Test error:', loss.eval(session=sess, feed_dict = {x:new_x_test, y_:new_y_test}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
